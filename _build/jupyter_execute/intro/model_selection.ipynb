{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "\n",
    "```{figure} https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png\n",
    ":align: center\n",
    "```\n",
    "\n",
    "## Underfitting\n",
    "\n",
    "* the model is too simple\n",
    "* the number of parameters is too low\n",
    "\n",
    "## Overfitting\n",
    "\n",
    "* the model is too complex\n",
    "* the number of parameters is too large\n",
    "\n",
    "## Train and test\n",
    "\n",
    "The common way to reveal overfitting is to use **train** and **test** datasets.\n",
    "\n",
    "* training dataset $\\mathcal D_{\\mathrm{train}} = (\\boldsymbol X_{\\mathrm{train}}, \\boldsymbol y_{\\mathrm{train}})$ is used on learning stage:\n",
    "\n",
    "$$\n",
    "    \\mathcal L_{\\mathrm{train}}(\\boldsymbol \\theta) = \\frac 1{N_{\\mathrm{train}}}\\sum\\limits_{(\\boldsymbol x_i, y_i) \\in \\mathcal D_{\\mathrm{train}}} \\ell(y_i, f_{\\boldsymbol \\theta}(\\boldsymbol x_i)) \\to \\min\\limits_{\\boldsymbol \\theta}\n",
    "$$\n",
    "\n",
    "* test dataset $\\mathcal D_{\\mathrm{test}} = (\\boldsymbol X_{\\mathrm{test}}, \\boldsymbol y_{\\mathrm{test}})$ used for evlaluation of model's quality:\n",
    "\n",
    "$$\n",
    "    \\mathcal L_{\\mathrm{test}}(\\boldsymbol \\theta) = \\frac 1{N_{\\mathrm{test}}}\\sum\\limits_{(\\boldsymbol x_i, y_i) \\in \\mathcal D_{\\mathrm{test}}} \\ell(y_i, f_{\\boldsymbol \\theta}(\\boldsymbol x_i))\n",
    "$$\n",
    "\n",
    "\n",
    "```{figure} https://vitalflux.com/wp-content/uploads/2020/12/overfitting-and-underfitting-wrt-model-error-vs-complexity.png\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A classical example\n",
    "\n",
    "* Ground truth: $y(x) = \\frac 1{1 + 25x^2}$, $-2\\leqslant x \\leqslant 2$\n",
    "* Polynomial regression model: $f_{\\boldsymbol \\theta}(x) = \\sum\\limits_{k=0}^n \\theta_k x^k$\n",
    "* Training set: $X = \\Big\\{x_i = 4\\frac{i-1}{N-1} - 2\\Big\\}_{i=1}^N$\n",
    "\n",
    "* Test set: $\\tilde X = \\Big\\{\\tilde x_i = 4\\frac{i-0.5}{N-1} - 2\\Big\\}_{i=1}^{N-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss function â€” MSE: \n",
    "\n",
    "    $$\n",
    "    \\mathcal L_{\\mathrm{train}}(\\boldsymbol \\theta, X) = \\frac 1N \\sum\\limits_{i=1}^N (f_{\\boldsymbol \\theta}(x_i) - y_i)^2  \\to \\min\\limits_{\\boldsymbol \\theta}\n",
    "    $$\n",
    "\n",
    "* What is happening with test loss\n",
    "\n",
    "    $$\n",
    "    \\mathcal L_{\\mathrm{test}}(\\boldsymbol \\theta, \\tilde X) = \\frac 1N \\sum\\limits_{i=1}^N (f_{\\boldsymbol \\theta}(\\tilde x_i) - \\tilde y_i)^2\n",
    "    $$\n",
    "    \n",
    "as $n$ grows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import rc\n",
    "from scipy.special import expit\n",
    "\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex', preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "rc('text.latex', preamble=r'\\usepackage[russian]{babel}')\n",
    "\n",
    "font = {'family' : 'monospace',\n",
    "        'size'   : 24,\n",
    "        'weight' : 'heavy'\n",
    "       }\n",
    "\n",
    "rc('font', **font)\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "def y(x):\n",
    "    return 1./(1 + 25*x**2)\n",
    "\n",
    "def plot_runge_train(l):\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    xs = np.linspace(-2, 2, num=500)\n",
    "    plt.plot(xs, y(xs), lw=2, c='r', label=r\"$y=\\frac 1{1+25x^2}$\")\n",
    "    train = np.linspace(-2, 2, num=l)\n",
    "    test = train[:-1] + 2 / (l - 1)\n",
    "    plt.scatter(train, y(train), c='b', label=\"train\")\n",
    "    plt.scatter(test, y(test), c='w', edgecolor='b', linewidth=1.5, label=\"test\")\n",
    "    plt.title(r\"$N = {}$\".format(l))\n",
    "    plt.legend()\n",
    "    plt.grid(ls=':')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def X(x, n):\n",
    "    res = [np.ones_like(x)]\n",
    "    for i in range(1, n+1):\n",
    "        res.append(x**i)\n",
    "    return np.vstack(res).T\n",
    "\n",
    "def plot_runge_model(l, n):\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    xs = np.linspace(-2, 2, num=500)\n",
    "    plt.plot(xs, y(xs), lw=2, c='r', ls=\"--\", label=r\"$y=\\frac 1{1+25x^2}$\")\n",
    "    train = np.linspace(-2, 2, num=l)\n",
    "    test = train[:-1] + 2 / (l - 1)\n",
    "    plt.scatter(train, y(train), c='b', label=\"train\")\n",
    "    plt.scatter(test, y(test), c='w', edgecolor='b', linewidth=1.5, label=\"test\")\n",
    "    \n",
    "    X_train = X(train, n)\n",
    "    X_test = X(test, n)\n",
    "    lin_reg = LinearRegression(fit_intercept=False)\n",
    "    lin_reg.fit(X_train, y(X_train))\n",
    "    ys = lin_reg.predict(X(xs, n))\n",
    "    plt.plot(xs, ys[:, 1], c='g', lw=2, label=r\"$f_\\theta(x)$\")\n",
    "    plt.legend()\n",
    "    plt.title(r\"$N = {}, n={}$\".format(l, n))\n",
    "    plt.grid(ls=':')\n",
    "    \n",
    "def plot_runge_scores(l, ns):\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    train = np.linspace(-2, 2, num=l)\n",
    "    test = train[:-1] + 2 / (l - 1)\n",
    "    train_score, test_score = [], []\n",
    "    for n in ns:\n",
    "        X_train = X(train, n)\n",
    "        X_test = X(test, n)\n",
    "        lin_reg = LinearRegression(fit_intercept=False)\n",
    "        lin_reg.fit(X_train, y(X_train))\n",
    "        train_score.append(np.mean((lin_reg.predict(X_train) - y(X_train))**2))\n",
    "        test_score.append(np.mean((lin_reg.predict(X_test) - y(X_test))**2))\n",
    "        \n",
    "    plt.semilogy(ns, train_score, c='r', lw=2, label=r\"train loss\")\n",
    "    plt.semilogy(ns, test_score, c='b', lw=2, label=r\"test loss\")\n",
    "    plt.xlim(ns[0], ns[-1])\n",
    "    plt.xlabel(r\"$n$\")\n",
    "    plt.ylabel(r\"$\\mathcal L$\")\n",
    "    plt.legend()\n",
    "    plt.title(r\"Scores, $N={}$\".format(l))\n",
    "    plt.grid(ls=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_runge_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_runge_train\u001b[49m(\u001b[38;5;241m25\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_runge_train' is not defined"
     ]
    }
   ],
   "source": [
    "plot_runge_train(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_runge_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_runge_model\u001b[49m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_runge_model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_runge_model(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_runge_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_runge_scores\u001b[49m(\u001b[38;5;241m50\u001b[39m, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m40\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_runge_scores' is not defined"
     ]
    }
   ],
   "source": [
    "plot_runge_scores(50, np.arange(2, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overfitting is a big problem in ML because an overfitted model makes poor predictions. The first signal of the overfitting: $\\mathcal L_{\\mathrm{train}} \\ll \\mathcal L_{\\mathrm{test}}$.\n",
    "\n",
    "## Cross validation\n",
    "\n",
    "```{figure} https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\n",
    ":align: center\n",
    "```\n",
    "\n",
    "```{admonition} TODO\n",
    ":class: warning\n",
    "\n",
    "* Add some text and original pictures\n",
    "* Make Runge example interactive\n",
    "* Show underfitting and overfitting on some real datasets\n",
    "* Use comparison of k-NN and linear regression as it is done in the section 2.3 of {cite}`hastie2009elements`\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}