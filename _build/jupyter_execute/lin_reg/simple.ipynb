{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple linear regression\n",
    "\n",
    "In case of one feature ($d=1$) linear regression is written as\n",
    "\n",
    "```{math}\n",
    "    :label: simple-lin-reg\n",
    "    y = a x + b.\n",
    "```\n",
    "\n",
    "The parameters of this model $\\boldsymbol \\theta = (a, b)$, where\n",
    "$b$ is **intercept** (or **bias**), $a$ is **slope**. \n",
    "\n",
    "The {ref}`feature matrix <feature-matrix>` here has only one column, denote it $\\boldsymbol x$ and let $\\boldsymbol y$ be the vector of corresponding labels. Also denote\n",
    "\n",
    "* $\\overline {\\boldsymbol x} = \\frac 1n \\sum\\limits_{i=1}^n x_i$ — sample mean of predictors;\n",
    "* $\\overline {\\boldsymbol y} = \\frac 1n \\sum\\limits_{i=1}^n y_i$ — sample mean of targets.\n",
    "\n",
    "## MSE fit\n",
    "\n",
    "Use MSE to fit parameters $\\boldsymbol \\theta = (a, b)$:\n",
    "\n",
    "```{math}\n",
    ":label: 1-d-mse\n",
    "\\mathcal L(a, b) =  \\frac 1n\\sum\\limits_{i=1}^n (y_i - ax_i - b)^2 \\to \\min\\limits_{a, b}.\n",
    "```\n",
    "   \n",
    "\n",
    "\n",
    "````{admonition} What about some calculus?\n",
    ":class: dropdown\n",
    "We have\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial \\mathcal L}{\\partial a} = -\\frac 2n\\sum\\limits_{i=1}^n x_i(y_i - ax_i - b) = 0,\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial \\mathcal L}{\\partial b} = -\\frac 2n\\sum\\limits_{i=1}^n (y_i - ax_i - b) = 0.\n",
    "$$\n",
    "\n",
    "From the last equality it follows that\n",
    "\n",
    "$$\n",
    "    b = \\overline {\\boldsymbol y} - a \\overline {\\boldsymbol x} \n",
    "$$\n",
    "\n",
    "TODO: Finish the proof\n",
    "````\n",
    "\n",
    "The optimal parameters are\n",
    "\n",
    "```{math}\n",
    "    :label: 1-d-weights\n",
    "    \\widehat a = \\frac{\\sum\\limits_{i=1}^n (x_i - \\overline {\\boldsymbol x})(y_i - \\overline {\\boldsymbol y})}{\\sum\\limits_{i=1}^n (x_i - \\overline {\\boldsymbol x})^2}, \\quad \n",
    "    \\widehat b = \\overline {\\boldsymbol y} - \\widehat a \\overline {\\boldsymbol x}.\n",
    "```\n",
    "\n",
    "Note that the slope is equal to the ratio of sample correlation between $\\boldsymbol x$ and $\\boldsymbol y$ to the sample variance of $\\boldsymbol x$.\n",
    "\n",
    "```{admonition} Question\n",
    ":class: important\n",
    "Does {eq}`1-d-weights` work for all possible values of $\\boldsymbol x$ and $\\boldsymbol y$?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy model\n",
    "\n",
    "The model {eq}`simple-lin-reg` is simple but we can do even simpler! Let $a=0$ and predict labels by a **constant** (or **dummy**) model $\\widehat y = b$. In fact, for constant predictions you don't need any features, only labels do the job.\n",
    "\n",
    "```{admonition} Question\n",
    ":class: important\n",
    "Which value of $b$ minimizes the MSE {eq}`1-d-mse`?\n",
    "```\n",
    "\n",
    "Linear regression can be used with different loss functions. For example, we can choose mean absolute error (MAE) instead of MSE:\n",
    "\n",
    "```{math}\n",
    ":label: 1-d-mae\n",
    "\\mathcal L(a, b) =  \\frac 1n\\sum\\limits_{i=1}^n \\vert y_i - ax_i - b\\vert \\to \\min\\limits_{a, b}.\n",
    "```\n",
    "\n",
    "This time it is unlikely that we can find the analytical solution. But maybe it can be done for the dummy model?\n",
    "\n",
    "````{admonition} Question\n",
    ":class: important\n",
    "For which value of $b$ the value of MAE\n",
    "\n",
    "$$\n",
    "     \\frac 1n\\sum\\limits_{i=1}^n \\vert y_i - b\\vert\n",
    "$$\n",
    "\n",
    "is minimal?\n",
    "\n",
    "```{admonition} Answer\n",
    ":class: tip, dropdown\n",
    "$\\widehat b = \\mathrm{med}(\\boldsymbol y)$ (see [this discussion](https://math.stackexchange.com/questions/113270/the-median-minimizes-the-sum-of-absolute-deviations-the-ell-1-norm) for details)\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSS and $R^2$-score\n",
    "\n",
    "Putting the optimal weights $\\widehat a$ and $\\widehat b$ into the loss function {eq}`1-d-mse`, we obtain **residual square error** (RSE). Multiplying by $n$ we get **residual sum of squares**\n",
    "\n",
    "$$\n",
    "    RSS = \\sum\\limits_{i=1}^n(y_i - \\widehat a x_i - \\widehat b)^2.\n",
    "$$\n",
    "\n",
    "Also, **total sum of squares** is defined as\n",
    "\n",
    "$$\n",
    "TSS = \\sum\\limits_{i=1}^n(y_i - \\overline {\\boldsymbol y})^2.\n",
    "$$\n",
    "\n",
    "A popular metric called **coefficient of determination** (or **$R^2$-score**) is defined as\n",
    "\n",
    "```{math}\n",
    ":label: R2-score\n",
    "R^2 = 1 - \\frac{RSS}{TSS} = 1 - \\frac{\\sum\\limits_{i=1}^n(y_i - \\widehat y_i)^2}{\\sum\\limits_{i=1}^n(y_i - \\overline {\\boldsymbol y})^2}.\n",
    "```\n",
    "\n",
    "The coefficient of determination shows proportion of variance explained. $R^2$-score does not exceed $1$ (the greater —  the better)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"display:none\" id=\"R2_dummy\">W3sicXVlc3Rpb24iOiAiV2hhdCBpcyB0aGUgJFJeMiQtc2NvcmUgb2YgdGhlIGR1bW15IG1vZGVsICRcXHdpZGVoYXQgeSA9IFxcb3ZlcmxpbmUge1xcYm9sZHN5bWJvbCB5fSQ/IiwgInR5cGUiOiAibnVtZXJpYyIsICJhbnN3ZXJzIjogW3sidHlwZSI6ICJ2YWx1ZSIsICJ2YWx1ZSI6IDAsICJjb3JyZWN0IjogdHJ1ZSwgImZlZWRiYWNrIjogIllvdSBuYWlsZWQgaXQhICRSXjIgPSAxIC0gMSA9IDAkIn0sIHsidHlwZSI6ICJ2YWx1ZSIsICJ2YWx1ZSI6IDEsICJjb3JyZWN0IjogZmFsc2UsICJmZWVkYmFjayI6ICJObywgaXQgc2hvdWxkIGJlIHN1YnRyYWN0ZWQgZnJvbSAkMSQifSwgeyJ0eXBlIjogInJhbmdlIiwgInJhbmdlIjogWy0xMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMCwgMF0sICJmZWVkYmFjayI6ICIkUl4yJC1zY29yZSBtdXN0IGJlIGJldHdlZW4gMCBhbmQgMSJ9LCB7InR5cGUiOiAicmFuZ2UiLCAicmFuZ2UiOiBbMS4wMDAwMDAwMDAxLCAxMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMF0sICJmZWVkYmFjayI6ICIkUl4yJC1zY29yZSBtdXN0IGJlIGJldHdlZW4gMCBhbmQgMSJ9LCB7InR5cGUiOiAiZGVmYXVsdCIsICJmZWVkYmFjayI6ICJUaGlzIHZhbHVlIGxvb2tzIGluY29ycmVjdCJ9XX1d</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jupyterquiz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjupyterquiz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display_quiz\n\u001b[1;32m      2\u001b[0m display_quiz(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#R2_dummy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jupyterquiz'"
     ]
    }
   ],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "display_quiz(\"#R2_dummy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$-score measures the amount of variability that is left unexplained after performing the regression. It shows how better the model works in comparison with dummy prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(boston-simple)=\n",
    "## Example: Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m boston \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../ISLP_datsets/Boston.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m boston\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "boston = pd.read_csv(\"../ISLP_datsets/Boston.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let predictors be `lstat`, target — `medv`. Let's calculate the regression coefficients using {eq}`1-d-weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m boston[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m boston[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedv\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = boston['lstat']\n",
    "y = boston['medv']\n",
    "a = np.sum((x -x.mean()) * (y - y.mean())) /  np.sum((x -x.mean()) ** 2)\n",
    "b = y.mean() - a*x.mean()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the data and the regression line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m font \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserif\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m   : \u001b[38;5;241m17\u001b[39m,\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m        }\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mrc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfont)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "font = {'family' : 'serif',\n",
    "        'size'   : 17,\n",
    "        'weight' : 'normal'\n",
    "       }\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', titlesize=18)\n",
    "# plt.rc('legend', fontsize=18)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "plt.rc('text.latex', preamble=r'\\usepackage[T2A]{fontenc}')\n",
    "plt.rc('text.latex', preamble=r'\\usepackage[russian]{babel}')\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInlineBackend.figure_format = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x, y, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.scatter(x, y, s=10, c='b', alpha=0.7)\n",
    "xs = np.linspace(x.min(), x.max(), num=10)\n",
    "plt.plot(xs, a*xs + b, c='r', lw=2, label=r\"$y = \\widehat a x + \\widehat b$\")\n",
    "plt.plot([xs.min(), xs.max()], [y.mean(), y.mean()], c='orange', lw=2, label=r\"$y = \\overline y$\")\n",
    "plt.xlabel(\"lstat\")\n",
    "plt.ylabel(\"medv\")\n",
    "plt.title(\"Simple linear regression vs dummy model\")\n",
    "plt.legend()\n",
    "plt.grid(ls=\":\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mse_lin_reg \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean((y \u001b[38;5;241m-\u001b[39m a\u001b[38;5;241m*\u001b[39mx \u001b[38;5;241m-\u001b[39m b)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m mse_dummy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((y \u001b[38;5;241m-\u001b[39m y\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear regression MSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mse_lin_reg)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "mse_lin_reg = np.mean((y - a*x - b)**2)\n",
    "mse_dummy = np.mean((y - y.mean())**2)\n",
    "print(\"Linear regression MSE:\", mse_lin_reg)\n",
    "print(\"Dummy model MSE:\", mse_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient of determination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mse_lin_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2-score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mmse_lin_reg\u001b[49m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((y \u001b[38;5;241m-\u001b[39m y\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDummy R2-score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m mse_dummy \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((y \u001b[38;5;241m-\u001b[39m y\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mse_lin_reg' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"R2-score:\", 1 - mse_lin_reg / np.mean((y - y.mean())**2))\n",
    "print(\"Dummy R2-score:\", 1 - mse_dummy / np.mean((y - y.mean())**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the linear regression line can be found automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msb\u001b[39;00m\n\u001b[1;32m      3\u001b[0m sb\u001b[38;5;241m.\u001b[39mregplot(boston, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstat\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m            scatter_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m}, line_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \n\u001b[1;32m      5\u001b[0m            )\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBoston linear regression\u001b[39m\u001b[38;5;124m'\u001b[39m);\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.regplot(boston, x=\"lstat\", y=\"medv\",\n",
    "           scatter_kws={\"color\": \"blue\", \"s\": 10}, line_kws={\"color\": \"red\"}, \n",
    "           ).set_title('Boston linear regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression from `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      3\u001b[0m LR \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m      4\u001b[0m x_reshaped \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "x_reshaped = x.values.reshape(-1, 1)\n",
    "LR.fit(x_reshaped, y)\n",
    "print(\"intercept:\", LR.intercept_)\n",
    "print(\"slope:\", LR.coef_[0])\n",
    "print(\"r-score:\", LR.score(x_reshaped, y))\n",
    "print(\"MSE:\", np.mean((LR.predict(x_reshaped) - y) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this with dummy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dummy_mse \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean((y \u001b[38;5;241m-\u001b[39m y\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(dummy_mse)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "dummy_mse = np.mean((y - y.mean())**2)\n",
    "print(dummy_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Prove that $\\frac 1n \\sum\\limits_{i=1}^n (x_i - \\overline {\\boldsymbol x})^2 = \\overline {\\boldsymbol x^2}  - (\\overline {\\boldsymbol x})^2$ where $\\overline {\\boldsymbol x^2} = \\frac 1n\\sum\\limits_{i=1}^n x_i^2$.\n",
    "\n",
    "```{admonition} TODO\n",
    ":class: warning\n",
    "* Finish analytical derivation of $a$ and $b$\n",
    "* Add some quizzes\n",
    "* Add more datasets (may me even simulated)\n",
    "* Think about cases where the performance of linear model is poor\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}